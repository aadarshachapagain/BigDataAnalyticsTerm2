{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group_Project1d_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import contractions \n",
        "from collections import defaultdict\t\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxkG286eUUq8",
        "outputId": "c63f4107-893e-48df-c581-42fe5dcd3a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.66-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 28.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85435 sha256=d6aad7f07f7cd45acd8e0dc120d18913372bc59d7e4fd66d634b07bba5684b7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.1.66 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import base_prefix\n",
        "\n",
        "\n",
        "class Text_preprocessor:\n",
        " \"\"\"\n",
        "    A class to preprocess text for NLP Application.\n",
        "\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    spec_filtered : list\n",
        "      list with special character removed\n",
        "    rm_stopwrds : list\n",
        "      list with stopwords removed\n",
        "    clean : list\n",
        "      list after all text preprocessing\n",
        "    index_word : dict\n",
        "      dict of indexed words\n",
        "    bag_of_words : list\n",
        "      list of words after preprocessing document\n",
        "    corpus_words: list\n",
        "      list of all words in corpus\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    expand_contraction(text=\"\"):\n",
        "        returns the expanded text.\n",
        "\n",
        "    remove_special_characters(text=\"\")\n",
        "        returns text with removed emailaddress, special characters and numbers\n",
        "\n",
        "    tokenize(text=\")\n",
        "        returns list of words from text\n",
        "    \n",
        "    removal_stop_words(token=[],language='english')\n",
        "        stop words are derived from  nltk.corpus\n",
        "        returns the list with removed stopwords for english language\n",
        "    \n",
        "    stem_or_lem(token=[],method=\"stemm\")\n",
        "        return the list after lemmitization or stemmization depending upon \n",
        "        method argument\n",
        "    \n",
        "    preprocessed_text(text=\"\")\n",
        "        returns list of words after performing\n",
        "        contaraction, removal of special characters, tokenization, removal of\n",
        "        stop word, stemmization and lemmitization\n",
        "\n",
        "    bow(documents)\n",
        "        returns bag of words for a document(sentence)\n",
        "\n",
        "    get_corpus_words(text)\n",
        "        return list of all  words of corpus \n",
        "\n",
        "    get_doc_list\n",
        "        return list of document after text-preprocessing\n",
        "\n",
        "    get_word_dict\n",
        "        returns key value pair for words in document\n",
        "\n",
        "    computeTF\n",
        "        return dict of computed TF for documents\n",
        "\n",
        "    computeTFIDF\n",
        "        returns dict of IDFS for words in corpus\n",
        "\n",
        "    computeTFIDF\n",
        "        returns dict of computed TFIDF for words in documents\n",
        "    \"\"\"\n",
        "\n",
        " \n",
        " def __init__(self):\n",
        "   self.spec_filtered = []\n",
        "   self.rm_stopwrds = []\n",
        "   self.clean = []\n",
        "   self.index_word = {}\n",
        "   self.bag_of_words = []\n",
        "   self.corpus_words = []\n",
        "\n",
        " def expand_contraction(self, text:str)->str:\n",
        "    '''\n",
        "    Expands the words in text with contractions module.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : str,\n",
        "            text to be expanded\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        text with expanded words \n",
        "    '''\n",
        "    # create an empty list\n",
        "    expanded_words = []    \n",
        "    for word in text.split():\n",
        "      # using contractions.fix to expand the shotened words and removes extra spaces\n",
        "      expanded_words.append(contractions.fix(word))   \n",
        "    expanded_text = ' '.join(expanded_words)\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        " def remove_special_characters(self, text:str)->str:\n",
        "      '''\n",
        "    Removes the email, special character and numbers from text.\n",
        "\n",
        "        Special character includes ! @ # $ & * () + -.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : str\n",
        "            String containing special character\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        String without email, special character and numbers\n",
        "    '''\n",
        "      # remove email if any\n",
        "      txt_email = re.compile(r'[A-Za-z0-9]*@[A-Za-z]*\\.com')\n",
        "      cln_txt = txt_email.sub('', text)\n",
        "      # remove special character and number if any\n",
        "      self.spec_filtered = re.sub('[^A-Za-z]+', ' ', cln_txt)      \n",
        "      return self.spec_filtered\n",
        "\n",
        " def tokenize(self,text:str)->list:\n",
        "   '''\n",
        "     Tokenize the text  to form list.\n",
        "        Use nltk.word_tokenize.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : str, \n",
        "        text to  tokenize\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        list of tokenized words\n",
        "    '''\n",
        "\n",
        "   nltk_tokens = nltk.word_tokenize(text)\n",
        "   return nltk_tokens\n",
        "\n",
        "\n",
        " def removal_stop_words(self,tokens:list, language:str='english')->list:\n",
        "   '''\n",
        "    Removes the stop words from list.\n",
        "\n",
        "        Use stopwords from nltk.corpus.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token : list\n",
        "            words token\n",
        "        language : str, optional \n",
        "        Language of the words (default is english) \n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list of words without stop words\n",
        "    '''\n",
        "   stopword_list = nltk.corpus.stopwords.words(language)\n",
        "   self.rm_stopwrds = [word for word in tokens if not word in stopword_list]\n",
        "   return self.rm_stopwrds\n",
        "\n",
        " def stem_or_lem(self, tokens:list,method:str)->list:\n",
        "   '''\n",
        "    Perform Stemming or lemmatization.\n",
        "    If the argument method is 'stemm' then performs stemmization, performs\n",
        "    lemmitization if 'lemm' and return tokens for mismatched strings\n",
        "    PorterStemmer  from nltk for stemming\n",
        "    WordNetLemmatizer from nltk for lemmatization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        tokens : list\n",
        "           list of tokenized words\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        return words after Stemming or Lemmatization\n",
        "    '''\n",
        "   #instance of PorterStemmer \n",
        "   ps = PorterStemmer()\n",
        "   stemmed=[]\n",
        "   lemmed=[]\n",
        "   if method =='stemm':\n",
        "    for w in tokens:\n",
        "        rootWord=ps.stem(w)\n",
        "        stemmed.append(rootWord)\n",
        "    return stemmed\n",
        "   elif method =='lemm':\n",
        "     wordnet_lemmatizer = WordNetLemmatizer()\n",
        "     for w in tokens:\n",
        "        lemm = wordnet_lemmatizer.lemmatize(w)\n",
        "        lemmed.append(lemm)\n",
        "     return lemmed\n",
        "   else:\n",
        "      return tokens\n",
        "\n",
        " def preprocessed_text(self,text:str)->list:\n",
        "    '''\n",
        "    Perfoms all the operation of text preprocessing.\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : str, \n",
        "            string to be preprocessed\n",
        "        Returns\n",
        "        -------\n",
        "        returns list of words after performing\n",
        "        contaraction, removal of special characters, tokenization, removal of\n",
        "        stop word, stemmization and lemmitization\n",
        "\n",
        "    '''\n",
        "    exp_text=self.expand_contraction(text)\n",
        "    prune_special=self.remove_special_characters(exp_text)\n",
        "    tokenize_words=self.tokenize(prune_special)\n",
        "    remove_stopwords=self.removal_stop_words(tokenize_words,'english')\n",
        "    stemmed =self.stem_or_lem(remove_stopwords,'stemm')\n",
        "    self.clean =self.stem_or_lem(stemmed,'lemm')\n",
        "    return self.clean\n",
        "\n",
        " def bow(self,sentence:str):\n",
        "   ''' \n",
        "   Create bag of words for a sentence\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      sentence: str\n",
        "        sentence to form bag of words\n",
        "\n",
        "    returns  bags of words for a sentence\n",
        "      \n",
        "   '''\n",
        "   self.bag_of_words = self.preprocessed_text(sentence)\n",
        "   return self.bag_of_words\n",
        " \n",
        " def get_corpus_words(self,text:list)->dict:\n",
        "    ''' \n",
        "    Creates list with all words from corpus\n",
        "\n",
        "        Parameter\n",
        "        --------\n",
        "        text : list\n",
        "          list of strings\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "         returns list  of words in corpus\n",
        "    '''\n",
        "    i = 0\n",
        "    # iterate through list of sentences\n",
        "    for sent in text:\n",
        "      clean_text = self.preprocessed_text(sent)\n",
        "      # iterate through words in sentence\n",
        "      for word in clean_text:\n",
        "        # unique words\n",
        "        if word not in self.corpus_words:\n",
        "          self.corpus_words.append(word)\n",
        "    return self.corpus_words\n",
        "\n",
        " def get_doc_list(self, text:list):\n",
        "    '''\n",
        "    Returns the list of all documents in the corpus\n",
        "\n",
        "      Parameter\n",
        "      ---------\n",
        "      text : list \n",
        "        list of documents before preprocessing\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "        list of documents after preprocessing\n",
        "   '''\n",
        "    arr = []\n",
        "    for sent in text:\n",
        "      bow = self.bow(sent)\n",
        "      # create dict for bag of words\n",
        "      word_dict = self.get_word_dict(text, bow)\n",
        "      # add the bow to list\n",
        "      arr.append(word_dict)\n",
        "    return arr\n",
        "\n",
        " def get_word_dict(self,text, bow):\n",
        "   '''\n",
        "    Returns the dict for bow\n",
        "\n",
        "      Parameter\n",
        "      ---------\n",
        "      text : list \n",
        "        list of documents before preprocessing\n",
        "\n",
        "      bow : list \n",
        "         list of words of a documents\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "        (key ,value) \n",
        "        Key : word\n",
        "        value : frequency of words in document\n",
        "   '''\n",
        "   \n",
        "   all_words = self.get_corpus_words(text)\n",
        "  #  words dictionary with value 0\n",
        "   wordDict = dict.fromkeys(all_words, 0) \n",
        "   for word in bow:\n",
        "    # count occurence of each words \n",
        "    wordDict[word] += 1\n",
        "   return  wordDict\n",
        "   \n",
        " def computeTF(self, wordDict,bow):\n",
        "      '''\n",
        "      Computes TF for each word in  BOW\n",
        "\n",
        "      Parameter\n",
        "      ---------\n",
        "        WordDict : dict \n",
        "          key : words\n",
        "          value: occurence of words in document\n",
        "\n",
        "          bow: list\n",
        "           Bag of words for the document\n",
        "\n",
        "      Returns\n",
        "      --------\n",
        "        dict\n",
        "        key : word\n",
        "        value : term frequency of the word\n",
        "\n",
        "      '''\n",
        "      tfDict = {}\n",
        "      bowCount = len(bow)\n",
        "      print(\"bowCount\",bowCount)\n",
        "      for word, count in wordDict.items():\n",
        "        # term frequency for words in a sentence\n",
        "          tfDict[word] = count/float(bowCount)\n",
        "      print(tfDict)\n",
        "      return tfDict\n",
        "\n",
        " def computeIDF(self, docList):\n",
        "    '''\n",
        "      Computes IDFs for all word in doclist\n",
        "\n",
        "      Parameter\n",
        "      ---------\n",
        "        doclist : list  \n",
        "          list of pre-processed documents\n",
        "\n",
        "      Returns\n",
        "      --------\n",
        "        dict\n",
        "        key : word\n",
        "        value : IDFS for each word\n",
        "\n",
        "      '''\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    # dict with all words with value 0(template)\n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                # increase the value if the word exist in doc\n",
        "                idfDict[word] += 1\n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / float(val))\n",
        "    return idfDict\n",
        "\n",
        " def computeTFIDF(self, tfBOW, idfs):\n",
        "    '''\n",
        "    Computes TFIDFs for all word in documents\n",
        "\n",
        "      Parameter\n",
        "      ---------\n",
        "        tfBow : dict  \n",
        "          Key: word\n",
        "          value: tf of word in document\n",
        "\n",
        "        idfs: dict\n",
        "          key : Word\n",
        "          value: idf of word in document list \n",
        "        \n",
        "\n",
        "      Returns\n",
        "      --------\n",
        "        dict\n",
        "        key : word\n",
        "        value : TfIDFS for each word in document\n",
        "\n",
        "    \n",
        "    '''\n",
        "    tfidf = {}\n",
        "    for word, val in tfBOW.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return tfidf\n",
        " \n",
        " def dict_to_df(self, text):\n",
        "   '''\n",
        "   Performs all above operations to \n",
        "   Generates pandas dafarame\n",
        "   \n",
        "\n",
        "      Parameter\n",
        "      ---------\n",
        "        text : list of documents (corpus)  \n",
        "                  \n",
        "\n",
        "      Returns\n",
        "      --------\n",
        "        Pandas dataframe\n",
        "    '''\n",
        "   arr = []\n",
        "   doclist = self.get_doc_list(text)\n",
        "   idfs = self.computeIDF(doclist)\n",
        "   for sent in text:\n",
        "     bow = self.bow(sent)\n",
        "     word_dict = self.get_word_dict(text,bow)\n",
        "     tfBOW = self.computeTF(word_dict,bow)\n",
        "    #  print(\"tfBOW\",tfBOW)\n",
        "     tfidf = self.computeTFIDF(tfBOW,idfs)\n",
        "     arr.append(tfidf)\n",
        "   df = pd.DataFrame(arr)\n",
        "   return df\n",
        "  \n",
        "text2 =['This is a good movie.',\n",
        "      'It is a good movie, but you know good is relative.',\n",
        "      'Movie is fun to watch.',\n",
        "      'I had a good relaxing time.',\n",
        "      'The whole cinema experience was good.',\n",
        "      'This is a good cinema.']\n",
        " \n",
        "  \n",
        "obj = Text_preprocessor()\n",
        "print(obj.dict_to_df(text2))\n",
        "obj.dict_to_df(text2)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "H_ZZINOBghCB",
        "outputId": "be1e935f-bd62-4037-a045-e0f9cab17b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bowCount 3\n",
            "{'thi': 0.3333333333333333, 'good': 0.3333333333333333, 'movi': 0.3333333333333333, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 6\n",
            "{'thi': 0.0, 'good': 0.3333333333333333, 'movi': 0.16666666666666666, 'It': 0.16666666666666666, 'know': 0.16666666666666666, 'rel': 0.16666666666666666, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 3\n",
            "{'thi': 0.0, 'good': 0.0, 'movi': 0.3333333333333333, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.3333333333333333, 'watch': 0.3333333333333333, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 4\n",
            "{'thi': 0.0, 'good': 0.25, 'movi': 0.0, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.25, 'relax': 0.25, 'time': 0.25, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 5\n",
            "{'thi': 0.0, 'good': 0.2, 'movi': 0.0, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.2, 'whole': 0.2, 'cinema': 0.2, 'experi': 0.2}\n",
            "bowCount 3\n",
            "{'thi': 0.3333333333333333, 'good': 0.3333333333333333, 'movi': 0.0, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.3333333333333333, 'experi': 0.0}\n",
            "       thi      good      movi        It  ...      the    whole    cinema   experi\n",
            "0  0.15904  0.026394  0.100343  0.000000  ...  0.00000  0.00000  0.000000  0.00000\n",
            "1  0.00000  0.026394  0.050172  0.129692  ...  0.00000  0.00000  0.000000  0.00000\n",
            "2  0.00000  0.000000  0.100343  0.000000  ...  0.00000  0.00000  0.000000  0.00000\n",
            "3  0.00000  0.019795  0.000000  0.000000  ...  0.00000  0.00000  0.000000  0.00000\n",
            "4  0.00000  0.015836  0.000000  0.000000  ...  0.15563  0.15563  0.095424  0.15563\n",
            "5  0.15904  0.026394  0.000000  0.000000  ...  0.00000  0.00000  0.159040  0.00000\n",
            "\n",
            "[6 rows x 15 columns]\n",
            "bowCount 3\n",
            "{'thi': 0.3333333333333333, 'good': 0.3333333333333333, 'movi': 0.3333333333333333, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 6\n",
            "{'thi': 0.0, 'good': 0.3333333333333333, 'movi': 0.16666666666666666, 'It': 0.16666666666666666, 'know': 0.16666666666666666, 'rel': 0.16666666666666666, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 3\n",
            "{'thi': 0.0, 'good': 0.0, 'movi': 0.3333333333333333, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.3333333333333333, 'watch': 0.3333333333333333, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 4\n",
            "{'thi': 0.0, 'good': 0.25, 'movi': 0.0, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.25, 'relax': 0.25, 'time': 0.25, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n",
            "bowCount 5\n",
            "{'thi': 0.0, 'good': 0.2, 'movi': 0.0, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.2, 'whole': 0.2, 'cinema': 0.2, 'experi': 0.2}\n",
            "bowCount 3\n",
            "{'thi': 0.3333333333333333, 'good': 0.3333333333333333, 'movi': 0.0, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.3333333333333333, 'experi': 0.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e63850f2-d7cf-4e73-8c84-c3c74ad33082\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thi</th>\n",
              "      <th>good</th>\n",
              "      <th>movi</th>\n",
              "      <th>It</th>\n",
              "      <th>know</th>\n",
              "      <th>rel</th>\n",
              "      <th>fun</th>\n",
              "      <th>watch</th>\n",
              "      <th>I</th>\n",
              "      <th>relax</th>\n",
              "      <th>time</th>\n",
              "      <th>the</th>\n",
              "      <th>whole</th>\n",
              "      <th>cinema</th>\n",
              "      <th>experi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.15904</td>\n",
              "      <td>0.026394</td>\n",
              "      <td>0.100343</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.026394</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.129692</td>\n",
              "      <td>0.129692</td>\n",
              "      <td>0.129692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100343</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259384</td>\n",
              "      <td>0.259384</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.019795</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.194538</td>\n",
              "      <td>0.194538</td>\n",
              "      <td>0.194538</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.015836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.15563</td>\n",
              "      <td>0.15563</td>\n",
              "      <td>0.095424</td>\n",
              "      <td>0.15563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.15904</td>\n",
              "      <td>0.026394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.159040</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e63850f2-d7cf-4e73-8c84-c3c74ad33082')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e63850f2-d7cf-4e73-8c84-c3c74ad33082 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e63850f2-d7cf-4e73-8c84-c3c74ad33082');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       thi      good      movi        It  ...      the    whole    cinema   experi\n",
              "0  0.15904  0.026394  0.100343  0.000000  ...  0.00000  0.00000  0.000000  0.00000\n",
              "1  0.00000  0.026394  0.050172  0.129692  ...  0.00000  0.00000  0.000000  0.00000\n",
              "2  0.00000  0.000000  0.100343  0.000000  ...  0.00000  0.00000  0.000000  0.00000\n",
              "3  0.00000  0.019795  0.000000  0.000000  ...  0.00000  0.00000  0.000000  0.00000\n",
              "4  0.00000  0.015836  0.000000  0.000000  ...  0.15563  0.15563  0.095424  0.15563\n",
              "5  0.15904  0.026394  0.000000  0.000000  ...  0.00000  0.00000  0.159040  0.00000\n",
              "\n",
              "[6 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bow = obj.bow(text2[0])\n",
        "bow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFACN58YUiNN",
        "outputId": "3b187b8a-605b-4cf2-aed7-8a33339dec68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thi', 'good', 'movi']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = obj.get_word_dict(text2,bow)\n",
        "word_dict\n"
      ],
      "metadata": {
        "id": "6fp71ic6qlT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e55d10f-eee6-4d5a-ac15-c9553be36750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': 0,\n",
              " 'It': 0,\n",
              " 'cinema': 0,\n",
              " 'experi': 0,\n",
              " 'fun': 0,\n",
              " 'good': 1,\n",
              " 'know': 0,\n",
              " 'movi': 1,\n",
              " 'rel': 0,\n",
              " 'relax': 0,\n",
              " 'the': 0,\n",
              " 'thi': 1,\n",
              " 'time': 0,\n",
              " 'watch': 0,\n",
              " 'whole': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfBOW = obj.computeTF(word_dict,bow)\n"
      ],
      "metadata": {
        "id": "1_ivC67hNaij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3469853-88c8-469f-f417-0b684d90e4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bowCount 3\n",
            "{'thi': 0.3333333333333333, 'good': 0.3333333333333333, 'movi': 0.3333333333333333, 'It': 0.0, 'know': 0.0, 'rel': 0.0, 'fun': 0.0, 'watch': 0.0, 'I': 0.0, 'relax': 0.0, 'time': 0.0, 'the': 0.0, 'whole': 0.0, 'cinema': 0.0, 'experi': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doclist = obj.get_doc_list(text2)\n",
        "idfs = obj.computeIDF(doclist)\n",
        "idfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWj4ekPCVI6s",
        "outputId": "e9d5b86b-a4d4-4591-8ea2-9340d381ef25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': 0.7781512503836436,\n",
              " 'It': 0.7781512503836436,\n",
              " 'cinema': 0.47712125471966244,\n",
              " 'experi': 0.7781512503836436,\n",
              " 'fun': 0.7781512503836436,\n",
              " 'good': 0.07918124604762482,\n",
              " 'know': 0.7781512503836436,\n",
              " 'movi': 0.3010299956639812,\n",
              " 'rel': 0.7781512503836436,\n",
              " 'relax': 0.7781512503836436,\n",
              " 'the': 0.7781512503836436,\n",
              " 'thi': 0.47712125471966244,\n",
              " 'time': 0.7781512503836436,\n",
              " 'watch': 0.7781512503836436,\n",
              " 'whole': 0.7781512503836436}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = obj.computeTFIDF(tfBOW,idfs)\n",
        "tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLGOaGd-VaYB",
        "outputId": "5c588752-13b4-4e36-8b34-28ceeeec7af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': 0.0,\n",
              " 'It': 0.0,\n",
              " 'cinema': 0.0,\n",
              " 'experi': 0.0,\n",
              " 'fun': 0.0,\n",
              " 'good': 0.026393748682541605,\n",
              " 'know': 0.0,\n",
              " 'movi': 0.10034333188799373,\n",
              " 'rel': 0.0,\n",
              " 'relax': 0.0,\n",
              " 'the': 0.0,\n",
              " 'thi': 0.15904041823988746,\n",
              " 'time': 0.0,\n",
              " 'watch': 0.0,\n",
              " 'whole': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WhZphzIbVfAD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}