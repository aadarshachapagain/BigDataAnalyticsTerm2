{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UlNs7KgtM0S"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EclhybSDtPYA",
    "outputId": "66a57ba8-cf17-4c7a-c014-768c715d96ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (0.1.66)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aadar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aadar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aadar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aadar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\aadar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\aadar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# !pip install contractions\n",
    "import sys  \n",
    "!{sys.executable} -m pip install contractions\n",
    " \n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import contractions \n",
    "from collections import defaultdict\t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from nltk.util import ngrams\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "# import en_core_web_sm\n",
    "# nlp = en_core_web_sm.load()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiHpQC6-tfkA"
   },
   "source": [
    "# Class Definition and Obj initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4ppaM5dtl9e",
    "outputId": "4fdbc2d3-91af-46ee-8bba-4a2a10632e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Gram tokenization:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Jack and',\n",
       " 'and jill',\n",
       " 'jill have',\n",
       " 'have made',\n",
       " 'made a',\n",
       " 'a delicious',\n",
       " 'delicious dish',\n",
       " 'dish Then',\n",
       " 'Then they',\n",
       " 'they started',\n",
       " 'started to',\n",
       " 'to play',\n",
       " 'play some',\n",
       " 'some game',\n",
       " 'game and',\n",
       " 'and jill',\n",
       " 'jill has',\n",
       " 'has attahacd',\n",
       " 'attahacd a',\n",
       " 'a photo',\n",
       " 'photo frame',\n",
       " 'frame to',\n",
       " 'to the',\n",
       " 'the straight',\n",
       " 'straight wall',\n",
       " 'wall and',\n",
       " 'and swung',\n",
       " 'swung on',\n",
       " 'on sea',\n",
       " 'sea saw',\n",
       " 'saw She',\n",
       " 'She was',\n",
       " 'was very',\n",
       " 'very happy',\n",
       " 'happy After',\n",
       " 'After the',\n",
       " 'the game',\n",
       " 'game they',\n",
       " 'they both',\n",
       " 'both went',\n",
       " 'went to',\n",
       " 'to central',\n",
       " 'central London',\n",
       " 'London to',\n",
       " 'to enjoy',\n",
       " 'enjoy some',\n",
       " 'some fast',\n",
       " 'fast food']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import base_prefix\n",
    "\n",
    "\n",
    "class Text_preprocessor:\n",
    "    \"\"\"\n",
    "       A class to preprocess text for NLP Application.\n",
    "\n",
    "       ...\n",
    "\n",
    "       Attributes\n",
    "       ----------\n",
    "       spec_filtered : list\n",
    "         list with special character removed\n",
    "       rm_stopwrds : list\n",
    "         list with stopwords removed\n",
    "       clean : list\n",
    "         list after all text preprocessing\n",
    "       index_word : dict\n",
    "         dict of indexed words\n",
    "       bag_of_words : df\n",
    "         list of words after preprocessing document\n",
    "\n",
    "\n",
    "       Methods\n",
    "       -------\n",
    "       expand_contraction(text=\"\"):\n",
    "           returns the expanded text.\n",
    "\n",
    "       remove_special_characters(text=\"\"):\n",
    "           returns text with removed emailaddress, special characters and numbers\n",
    "\n",
    "       tokenize(text=\")\n",
    "           returns list of words from text\n",
    "\n",
    "       removal_stop_words(token=[],language='english')\n",
    "           stop words are derived from  nltk.corpus\n",
    "           returns the list with removed stopwords for english language\n",
    "\n",
    "       stem_or_lem(token=[],method=\"stemm\")\n",
    "           return the list after lemmitization or stemmization depending upon \n",
    "           method argument\n",
    "\n",
    "       preprocessed_text(text=\"\")\n",
    "           returns list of words after performing\n",
    "           contaraction, removal of special characters, tokenization, removal of\n",
    "           stop word, stemmization and lemmitization\n",
    "\n",
    "       bow(document)\n",
    "           returns bag of words for a document(sentence)\n",
    "\n",
    "\n",
    "       get_word_dict\n",
    "           returns key value pair for words in document\n",
    "\n",
    "       computeTF\n",
    "           return dict of computed TF for documents\n",
    "\n",
    "       computeTFIDF\n",
    "           returns dict of IDFS for words in corpus\n",
    "\n",
    "       computeTFIDF\n",
    "           returns dict of computed TFIDF for words in documents\n",
    "\n",
    "       dict_to_df\n",
    "           returns pandas dataframe representing TFIDS of  list of documents of document\n",
    "       \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.spec_filtered = []\n",
    "        self.rm_stopwrds = []\n",
    "        self.clean = []\n",
    "        self.index_word = {}\n",
    "        self.bag_of_words = []\n",
    "        self.corpus_words = []\n",
    "        self.clean_document_list = []\n",
    "\n",
    "    def expand_contraction(self, text: str) -> str:\n",
    "        '''\n",
    "        Expands the words in text with contractions module.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            text : str,\n",
    "                text to be expanded\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            text with expanded words \n",
    "        '''\n",
    "        # create an empty list\n",
    "        expanded_words = []\n",
    "        for word in text.split():\n",
    "            # using contractions.fix to expand the shotened words and removes extra spaces\n",
    "            expanded_words.append(contractions.fix(word))\n",
    "        expanded_text = ' '.join(expanded_words)\n",
    "        return expanded_text.lower()\n",
    "\n",
    "    def remove_special_characters(self, text: str) -> str:\n",
    "        '''\n",
    "      Removes the email, special character and numbers from text.\n",
    "\n",
    "          Special character includes ! @ # $ & * () + - [].\n",
    "\n",
    "          Parameters\n",
    "          ----------\n",
    "          text : str\n",
    "              String containing special character\n",
    "\n",
    "          Returns\n",
    "          -------\n",
    "          String without email, special character and numbers\n",
    "      '''\n",
    "        # remove email if any\n",
    "        txt_email = re.compile(r'[A-Za-z0-9]*@[A-Za-z]*\\.com')\n",
    "        cln_txt = txt_email.sub('email', text)\n",
    "        # remove special character and number if any\n",
    "        self.spec_filtered = re.sub('[^A-Za-z]+', ' ', cln_txt)\n",
    "        return self.spec_filtered\n",
    "\n",
    "    def tokenize(self, text: str) -> list:\n",
    "        '''\n",
    "          Tokenize the text  to form list.\n",
    "             Use nltk.word_tokenize.\n",
    "\n",
    "             Parameters\n",
    "             ----------\n",
    "             text : str, \n",
    "             text to  tokenize\n",
    "\n",
    "             Returns\n",
    "             -------\n",
    "             list of tokenized words\n",
    "         '''\n",
    "\n",
    "        nltk_tokens = nltk.word_tokenize(text)\n",
    "        return nltk_tokens\n",
    "\n",
    "    def removal_stop_words(self, tokens: list, language: str = 'english') -> list:\n",
    "        '''\n",
    "         Removes the stop words from list.\n",
    "\n",
    "             Use stopwords from nltk.corpus.\n",
    "\n",
    "             Parameters\n",
    "             ----------\n",
    "             token : list\n",
    "                 words token\n",
    "             language : str, optional \n",
    "             Language of the words (default is english) \n",
    "\n",
    "             Returns\n",
    "             -------\n",
    "             list of words without stop words\n",
    "         '''\n",
    "        stopword_list = nltk.corpus.stopwords.words(language)\n",
    "        self.rm_stopwrds = [\n",
    "            word for word in tokens if not word in stopword_list]\n",
    "        return self.rm_stopwrds\n",
    "\n",
    "    def stem_or_lem(self, tokens: list, method: str) -> list:\n",
    "        '''\n",
    "         Perform Stemming or lemmatization.\n",
    "         If the argument method is 'stemm' then performs stemmization, performs\n",
    "         lemmitization if 'lemm' and return tokens for mismatched strings\n",
    "         PorterStemmer  from nltk for stemming\n",
    "         WordNetLemmatizer from nltk for lemmatization\n",
    "\n",
    "             Parameters\n",
    "             ----------\n",
    "             tokens : list\n",
    "                list of tokenized words\n",
    "\n",
    "             Returns\n",
    "             -------\n",
    "             return words after Stemming or Lemmatization\n",
    "         '''\n",
    "        # instance of PorterStemmer\n",
    "        ps = PorterStemmer()\n",
    "        stemmed = []\n",
    "        lemmed = []\n",
    "        if method == 'stemm':\n",
    "            for w in tokens:\n",
    "                rootWord = ps.stem(w)\n",
    "                stemmed.append(rootWord)\n",
    "            return stemmed\n",
    "        elif method == 'lemm':\n",
    "            wordnet_lemmatizer = WordNetLemmatizer()\n",
    "            for w in tokens:\n",
    "                lemm = wordnet_lemmatizer.lemmatize(w)\n",
    "                lemmed.append(lemm)\n",
    "            return lemmed\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "    def preprocessed_text(self, text: str) -> list:\n",
    "        '''\n",
    "        Perfoms all the operation of text preprocessing.\n",
    "\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            text : str, \n",
    "                string to be preprocessed\n",
    "            Returns\n",
    "            -------\n",
    "            returns list of words after performing\n",
    "            contaraction, removal of special characters, tokenization, removal of\n",
    "            stop word, stemmization and lemmitization\n",
    "\n",
    "        '''\n",
    "        exp_text = self.expand_contraction(text)\n",
    "        prune_special = self.remove_special_characters(exp_text)\n",
    "        tokenize_words = self.tokenize(prune_special)\n",
    "        remove_stopwords = self.removal_stop_words(tokenize_words, 'english')\n",
    "        # stemmed =self.stem_or_lem(remove_stopwords,'stemm')\n",
    "        self.clean = self.stem_or_lem(remove_stopwords, 'lemm')\n",
    "        return self.clean\n",
    "\n",
    "    def get_word_dict(self, dirty_text, document):\n",
    "        '''\n",
    "         Returns the dict of words after achieved after cleaning\n",
    "\n",
    "           Parameter\n",
    "           ---------\n",
    "           dirty_text : list \n",
    "             list of documents before preprocessing\n",
    "\n",
    "           document : list \n",
    "              list of string [raw_document]\n",
    "\n",
    "           Returns\n",
    "           -------\n",
    "             (key ,value) \n",
    "             Key : word\n",
    "             value : frequency of words in document\n",
    "        '''\n",
    "\n",
    "       #  all_words = self.get_corpus_words(text)\n",
    "        flatten_list = [item for sublist in self.pre_prep(\n",
    "            dirty_text) for item in sublist]\n",
    "        all_words = list(set(flatten_list))\n",
    "        clean_document = self.preprocessed_text(document)\n",
    "\n",
    "       #  words dictionary with value 0\n",
    "        wordDict = dict.fromkeys(all_words, 0)\n",
    "        for word in clean_document:\n",
    "            # count occurence of each words\n",
    "            if word in wordDict:\n",
    "                wordDict[word] += 1\n",
    "        return wordDict\n",
    "\n",
    "    def pre_prep(self, dirty_text: list) -> list:\n",
    "        '''\n",
    "          Returns the list  of documents of documents\n",
    "\n",
    "            Parameter\n",
    "            ---------\n",
    "            dirty_text : list \n",
    "              list of documents before preprocessing\n",
    "\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "              list of clean documents of clean document\n",
    "         '''\n",
    "        for document in dirty_text:\n",
    "            self.clean_document_list.append(self.preprocessed_text((document)))\n",
    "        return self.clean_document_list\n",
    "\n",
    "    def bow(self, dirty_text: list) -> list:\n",
    "        '''\n",
    "         Returns the bag of words in pandas dataframe format\n",
    "\n",
    "           Parameter\n",
    "           ---------\n",
    "           dirty_text : list \n",
    "             list of documents of raw_documents\n",
    "\n",
    "\n",
    "           Returns\n",
    "           -------\n",
    "             bag of words in pandas Df\n",
    "        '''\n",
    "\n",
    "        flatten_list = [item for sublist in self.pre_prep(\n",
    "            dirty_text) for item in sublist]\n",
    "        unique_words = list(set(flatten_list))\n",
    "        #  indexing the words from corpus\n",
    "        # first parameter  into keys and second is value(index)\n",
    "        indexed_words = dict(zip(unique_words, range(len(unique_words))))\n",
    "        bow_qrr = []\n",
    "        for document in self.clean_document_list:\n",
    "            #  create numpy array of of length of corpus\n",
    "            empty_arr = np.zeros(len(unique_words))\n",
    "            #  count the occurence of the each words\n",
    "            for word in document:\n",
    "                empty_arr[indexed_words[word]] += 1\n",
    "            bow_qrr.append(empty_arr)\n",
    "            #  convert array to dataframe\n",
    "        df = pd.DataFrame(bow_qrr, columns=unique_words)\n",
    "        return df\n",
    "\n",
    "    def computeTF(self, dirty_text: list, document) -> dict:\n",
    "        '''\n",
    "        Computes TF for each word in  document\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "          dirty_text : list documents of document\n",
    "\n",
    "            document: list\n",
    "             List of strings(raw_document)\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "          dict\n",
    "          key : word\n",
    "          value : term frequency of the word\n",
    "\n",
    "        '''\n",
    "        tfDict = {}\n",
    "        len_sntn = len(self.preprocessed_text(document))\n",
    "        word_dict = self.get_word_dict(dirty_text, document)\n",
    "        for word, count in word_dict.items():\n",
    "            # term frequency for words in a sentence\n",
    "            tfDict[word] = count/float(len_sntn)\n",
    "        return tfDict\n",
    "\n",
    "    def computeIDF(self, dirty_text: list) -> dict:\n",
    "        '''\n",
    "          Computes IDFs for all word in doclist\n",
    "\n",
    "          Parameter\n",
    "          ---------\n",
    "            dirty_text : list  \n",
    "              list of pre-processed documents\n",
    "\n",
    "          Returns\n",
    "          --------\n",
    "            dict\n",
    "            key : word\n",
    "            value : IDFS for each word\n",
    "\n",
    "          '''\n",
    "        doc_list = []\n",
    "        for doc in dirty_text:\n",
    "            word_dict = self.get_word_dict(dirty_text, doc)\n",
    "            doc_list.append(word_dict)\n",
    "\n",
    "        idfDict = {}\n",
    "        N = len(doc_list)\n",
    "        # dict with all words with value 0(template)\n",
    "        idfDict = dict.fromkeys(doc_list[0].keys(), 0)\n",
    "        for doc in doc_list:\n",
    "            for word, val in doc.items():\n",
    "                if val > 0:\n",
    "                    # increase the value if the word exist in doc\n",
    "                    idfDict[word] += 1\n",
    "        for word, val in idfDict.items():\n",
    "            idfDict[word] = math.log10(N / float(val))\n",
    "        return idfDict\n",
    "\n",
    "    def computeTFIDF(self, tf, idfs) -> dict:\n",
    "        '''\n",
    "        Computes TFIDFs for all word in documents\n",
    "\n",
    "          Parameter\n",
    "          ---------\n",
    "            tfBow : dict  \n",
    "              Key: word\n",
    "              value: tf of word in document\n",
    "            idfs: dict\n",
    "              key : Word\n",
    "              value: idf of word in document list \n",
    "\n",
    "\n",
    "          Returns\n",
    "          --------\n",
    "            dict\n",
    "            key : word\n",
    "            value : TfIDFS for each word in document\n",
    "\n",
    "        '''\n",
    "        tfidf = {}\n",
    "        for word, val in tf.items():\n",
    "            tfidf[word] = val*idfs[word]\n",
    "        return tfidf\n",
    "\n",
    "    def dict_to_df(self, text) -> list:\n",
    "        '''\n",
    "        Performs all above operations to \n",
    "        Generates pandas dafarame\n",
    "\n",
    "           Parameter\n",
    "           ---------\n",
    "             text : list of documents (corpus)  \n",
    "\n",
    "\n",
    "           Returns\n",
    "           --------\n",
    "             Pandas dataframe\n",
    "         '''\n",
    "        arr = []\n",
    "        idfs = self.computeIDF(text)\n",
    "        for doc in text:\n",
    "            tf = self.computeTF(text, doc)\n",
    "            tfidf = self.computeTFIDF(tf, idfs)\n",
    "            arr.append(tfidf)\n",
    "        df = pd.DataFrame(arr)\n",
    "        return df\n",
    "\n",
    "    def pos_identification(self, text) -> list:\n",
    "        '''\n",
    "        identifies Part of speech in given text \n",
    "\n",
    "           Parameter\n",
    "           ---------\n",
    "             text : string   \n",
    "\n",
    "\n",
    "           Returns\n",
    "           --------\n",
    "             list of tuple with identification\n",
    "\n",
    "        '''\n",
    "        return nltk.pos_tag(nltk.word_tokenize(self.remove_special_characters(text)))\n",
    "\n",
    "    def name_entity_identification(self, text: str, lib='spacy') -> list:\n",
    "        '''\n",
    "        identifies name or entity of text in given text \n",
    "\n",
    "           Parameter\n",
    "           ---------\n",
    "             text : string   \n",
    "\n",
    "\n",
    "           Returns\n",
    "           --------\n",
    "             list of tuple with identification\n",
    "\n",
    "        '''\n",
    "        #  use nltk for identification\n",
    "        if lib == 'nltk':\n",
    "            print(\"Using Nltk lib\")\n",
    "            for chunk in nltk.ne_chunk(self.pos_identification(text)):\n",
    "                if hasattr(chunk, 'label'):\n",
    "                    idntfy = ([(chunk.label(), chunk) for c in chunk])\n",
    "\n",
    "            # use spacy for identification\n",
    "        doc = nlp(obj.remove_special_characters(text))\n",
    "        idntfy = ([(X.text, X.label_) for X in doc.ents])\n",
    "        return ([(X.text, X.label_) for X in doc.ents])\n",
    "\n",
    "    def ngram_tokenization(self, text, n=2) -> list:\n",
    "        '''\n",
    "        identifies name or entity of text in given text \n",
    "\n",
    "           Parameter\n",
    "           ---------\n",
    "             text : string   \n",
    "\n",
    "\n",
    "           Returns\n",
    "           --------\n",
    "             list of tuple with identification\n",
    "\n",
    "        '''\n",
    "        n_grams = ngrams(nltk.word_tokenize(\n",
    "            obj.remove_special_characters(text)), n)\n",
    "        return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "\n",
    "text2 = ['This is a good movie.',\n",
    "         'It is a good movie, but you know good is relative.',\n",
    "         'Movie is fun to watch.',\n",
    "         'I had a good relaxing time.',\n",
    "         'The whole cinema experience was good.',\n",
    "         'This is a good cinema.']\n",
    "\n",
    "text3 = '    Jack and  jill have made a delicious,dish.Then they started to play some12 game! and jill has attahacd# [a] photo frame to the straight9 wall and swung on sea-saw. She was very happy. After the game, they both went to central London to enjoy some fast food.'\n",
    "\n",
    "\n",
    "obj = Text_preprocessor()\n",
    "\n",
    "\n",
    "# print(\"BOW:\")\n",
    "# print(obj.bow(text2))\n",
    "\n",
    "# print(\"TF for a sentence :\")\n",
    "# print(obj.computeTF(text2, text2[0]))\n",
    "\n",
    "# print(\"IDFS:\")\n",
    "# print(obj.computeIDF(text2))\n",
    "\n",
    "# print(\"TFIDFS:\")\n",
    "# print(obj.dict_to_df(text2))\n",
    "\n",
    "# print(\"Cleaning:\")\n",
    "# print(obj.remove_special_characters(text3))\n",
    "\n",
    "# print(\"POS Identification:\")\n",
    "# print(obj.pos_identification(text3))\n",
    "\n",
    "# print(\"Name Entity identification:\")\n",
    "# print(obj.name_entity_identification(text3))\n",
    "\n",
    "print(\"N Gram tokenization:\")\n",
    "obj.ngram_tokenization(text3, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wzdyu8E9uTT4"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vnKr2VLIuaAe"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "a=[]\n",
    "b=[]\n",
    "with open('./SMSSpamCollection.txt','r') as f:\n",
    "    l=f.readlines()\n",
    "    for j in l:\n",
    "        # append label in a (that is either spam or ham )\n",
    "        a.append(j.split('\\t')[0])\n",
    "        # actual email in b\n",
    "        b.append(j.split('\\t')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4b4hMH0au9hZ",
    "outputId": "ab692680-13f2-4308-bb62-26e4f5118f3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           document\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                    Ok lar... Joking wif u oni...\\n\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to pandas  dataframe\n",
    "d={'label':a,'document':b}\n",
    "df=pd.DataFrame(d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ekBRAiazvREv"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''Controls the shuffling applied to the data before applying the split. \n",
    "Pass an int for reproducible output across multiple function calls'''\n",
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Urfr7e0wTPx",
    "outputId": "11a479b0-8dbd-4e39-d0e4-b3b24081115d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OStLwfGrwV2w"
   },
   "outputs": [],
   "source": [
    "training_data_clean = (\n",
    "    # remove_special_character removes number email and special character \n",
    "    training_data.assign(clean_document = lambda x:[obj.remove_special_characters(text) for text in x.document])\n",
    "    # Tokenize word\n",
    "    .assign(word_token = lambda x:[obj.tokenize(text) for text in x.clean_document])\n",
    "    # remove stop words\n",
    "     .assign(stops= lambda x:[obj.removal_stop_words(text) for text in x.word_token])\n",
    "    # lemmitization\n",
    "     .assign(stemorlem= lambda x:[obj.stem_or_lem(text,'stemm') for text in x.stops])\n",
    "     # # input to sklearn\n",
    "    .assign(document_to_sklearn= lambda x: [\" \".join(map(str,list_of_words)) for list_of_words in x.stemorlem ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "IbHvSElRxl_o",
    "outputId": "bd64fc29-b063-4f8d-b138-57d2e9cb28db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>clean_document</th>\n",
       "      <th>word_token</th>\n",
       "      <th>stops</th>\n",
       "      <th>stemorlem</th>\n",
       "      <th>document_to_sklearn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you do online transaction?\\n</td>\n",
       "      <td>Can you do online transaction</td>\n",
       "      <td>[Can, you, do, online, transaction]</td>\n",
       "      <td>[Can, online, transaction]</td>\n",
       "      <td>[can, onlin, transact]</td>\n",
       "      <td>can onlin transact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>ham</td>\n",
       "      <td>See the forwarding message for proof\\n</td>\n",
       "      <td>See the forwarding message for proof</td>\n",
       "      <td>[See, the, forwarding, message, for, proof]</td>\n",
       "      <td>[See, forwarding, message, proof]</td>\n",
       "      <td>[see, forward, messag, proof]</td>\n",
       "      <td>see forward messag proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>ham</td>\n",
       "      <td>Same, I'm at my great aunts anniversary party ...</td>\n",
       "      <td>Same I m at my great aunts anniversary party i...</td>\n",
       "      <td>[Same, I, m, at, my, great, aunts, anniversary...</td>\n",
       "      <td>[Same, I, great, aunts, anniversary, party, ta...</td>\n",
       "      <td>[same, i, great, aunt, anniversari, parti, tar...</td>\n",
       "      <td>same i great aunt anniversari parti tarpon spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>ham</td>\n",
       "      <td>Apps class varaya elaya.\\n</td>\n",
       "      <td>Apps class varaya elaya</td>\n",
       "      <td>[Apps, class, varaya, elaya]</td>\n",
       "      <td>[Apps, class, varaya, elaya]</td>\n",
       "      <td>[app, class, varaya, elaya]</td>\n",
       "      <td>app class varaya elaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...</td>\n",
       "      <td>SMS ac Blind Date U Rodds is m from Aberdeen U...</td>\n",
       "      <td>[SMS, ac, Blind, Date, U, Rodds, is, m, from, ...</td>\n",
       "      <td>[SMS, ac, Blind, Date, U, Rodds, Aberdeen, Uni...</td>\n",
       "      <td>[sm, ac, blind, date, u, rodd, aberdeen, unit,...</td>\n",
       "      <td>sm ac blind date u rodd aberdeen unit kingdom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back, lemme know when you're ready\\n</td>\n",
       "      <td>I m back lemme know when you re ready</td>\n",
       "      <td>[I, m, back, lem, me, know, when, you, re, ready]</td>\n",
       "      <td>[I, back, lem, know, ready]</td>\n",
       "      <td>[i, back, lem, know, readi]</td>\n",
       "      <td>i back lem know readi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yo do you know anyone  &amp;lt;#&amp;gt;  or otherwise...</td>\n",
       "      <td>Yo do you know anyone lt gt or otherwise able ...</td>\n",
       "      <td>[Yo, do, you, know, anyone, lt, gt, or, otherw...</td>\n",
       "      <td>[Yo, know, anyone, lt, gt, otherwise, able, bu...</td>\n",
       "      <td>[yo, know, anyon, lt, gt, otherwis, abl, buy, ...</td>\n",
       "      <td>yo know anyon lt gt otherwis abl buy liquor ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ooh, 4got, i'm gonna start belly dancing in mo...</td>\n",
       "      <td>Ooh got i m gonna start belly dancing in mosel...</td>\n",
       "      <td>[Ooh, got, i, m, gon, na, start, belly, dancin...</td>\n",
       "      <td>[Ooh, got, gon, na, start, belly, dancing, mos...</td>\n",
       "      <td>[ooh, got, gon, na, start, belli, danc, mosele...</td>\n",
       "      <td>ooh got gon na start belli danc moseley wed u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>ham</td>\n",
       "      <td>Not really dude, have no friends i'm afraid :(\\n</td>\n",
       "      <td>Not really dude have no friends i m afraid</td>\n",
       "      <td>[Not, really, dude, have, no, friends, i, m, a...</td>\n",
       "      <td>[Not, really, dude, friends, afraid]</td>\n",
       "      <td>[not, realli, dude, friend, afraid]</td>\n",
       "      <td>not realli dude friend afraid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>spam</td>\n",
       "      <td>Urgent! Please call 09061213237 from a landlin...</td>\n",
       "      <td>Urgent Please call from a landline cash or a h...</td>\n",
       "      <td>[Urgent, Please, call, from, a, landline, cash...</td>\n",
       "      <td>[Urgent, Please, call, landline, cash, holiday...</td>\n",
       "      <td>[urgent, pleas, call, landlin, cash, holiday, ...</td>\n",
       "      <td>urgent pleas call landlin cash holiday await c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4459 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           document  \\\n",
       "3784   ham                   Can you do online transaction?\\n   \n",
       "2009   ham             See the forwarding message for proof\\n   \n",
       "3887   ham  Same, I'm at my great aunts anniversary party ...   \n",
       "2326   ham                         Apps class varaya elaya.\\n   \n",
       "305   spam  SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...   \n",
       "...    ...                                                ...   \n",
       "255    ham           I'm back, lemme know when you're ready\\n   \n",
       "2934   ham  Yo do you know anyone  &lt;#&gt;  or otherwise...   \n",
       "2191   ham  Ooh, 4got, i'm gonna start belly dancing in mo...   \n",
       "318    ham   Not really dude, have no friends i'm afraid :(\\n   \n",
       "5252  spam  Urgent! Please call 09061213237 from a landlin...   \n",
       "\n",
       "                                         clean_document  \\\n",
       "3784                     Can you do online transaction    \n",
       "2009              See the forwarding message for proof    \n",
       "3887  Same I m at my great aunts anniversary party i...   \n",
       "2326                           Apps class varaya elaya    \n",
       "305   SMS ac Blind Date U Rodds is m from Aberdeen U...   \n",
       "...                                                 ...   \n",
       "255              I m back lemme know when you re ready    \n",
       "2934  Yo do you know anyone lt gt or otherwise able ...   \n",
       "2191  Ooh got i m gonna start belly dancing in mosel...   \n",
       "318         Not really dude have no friends i m afraid    \n",
       "5252  Urgent Please call from a landline cash or a h...   \n",
       "\n",
       "                                             word_token  \\\n",
       "3784                [Can, you, do, online, transaction]   \n",
       "2009        [See, the, forwarding, message, for, proof]   \n",
       "3887  [Same, I, m, at, my, great, aunts, anniversary...   \n",
       "2326                       [Apps, class, varaya, elaya]   \n",
       "305   [SMS, ac, Blind, Date, U, Rodds, is, m, from, ...   \n",
       "...                                                 ...   \n",
       "255   [I, m, back, lem, me, know, when, you, re, ready]   \n",
       "2934  [Yo, do, you, know, anyone, lt, gt, or, otherw...   \n",
       "2191  [Ooh, got, i, m, gon, na, start, belly, dancin...   \n",
       "318   [Not, really, dude, have, no, friends, i, m, a...   \n",
       "5252  [Urgent, Please, call, from, a, landline, cash...   \n",
       "\n",
       "                                                  stops  \\\n",
       "3784                         [Can, online, transaction]   \n",
       "2009                  [See, forwarding, message, proof]   \n",
       "3887  [Same, I, great, aunts, anniversary, party, ta...   \n",
       "2326                       [Apps, class, varaya, elaya]   \n",
       "305   [SMS, ac, Blind, Date, U, Rodds, Aberdeen, Uni...   \n",
       "...                                                 ...   \n",
       "255                         [I, back, lem, know, ready]   \n",
       "2934  [Yo, know, anyone, lt, gt, otherwise, able, bu...   \n",
       "2191  [Ooh, got, gon, na, start, belly, dancing, mos...   \n",
       "318                [Not, really, dude, friends, afraid]   \n",
       "5252  [Urgent, Please, call, landline, cash, holiday...   \n",
       "\n",
       "                                              stemorlem  \\\n",
       "3784                             [can, onlin, transact]   \n",
       "2009                      [see, forward, messag, proof]   \n",
       "3887  [same, i, great, aunt, anniversari, parti, tar...   \n",
       "2326                        [app, class, varaya, elaya]   \n",
       "305   [sm, ac, blind, date, u, rodd, aberdeen, unit,...   \n",
       "...                                                 ...   \n",
       "255                         [i, back, lem, know, readi]   \n",
       "2934  [yo, know, anyon, lt, gt, otherwis, abl, buy, ...   \n",
       "2191  [ooh, got, gon, na, start, belli, danc, mosele...   \n",
       "318                 [not, realli, dude, friend, afraid]   \n",
       "5252  [urgent, pleas, call, landlin, cash, holiday, ...   \n",
       "\n",
       "                                    document_to_sklearn  \n",
       "3784                                 can onlin transact  \n",
       "2009                           see forward messag proof  \n",
       "3887  same i great aunt anniversari parti tarpon spring  \n",
       "2326                             app class varaya elaya  \n",
       "305   sm ac blind date u rodd aberdeen unit kingdom ...  \n",
       "...                                                 ...  \n",
       "255                               i back lem know readi  \n",
       "2934  yo know anyon lt gt otherwis abl buy liquor ou...  \n",
       "2191  ooh got gon na start belli danc moseley wed u ...  \n",
       "318                       not realli dude friend afraid  \n",
       "5252  urgent pleas call landlin cash holiday await c...  \n",
       "\n",
       "[4459 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "iQT32CmgyLLi",
    "outputId": "74602292-9382-448e-d5c2-1732a6288e6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>but</th>\n",
       "      <th>call</th>\n",
       "      <th>come</th>\n",
       "      <th>day</th>\n",
       "      <th>dont</th>\n",
       "      <th>free</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>today</th>\n",
       "      <th>txt</th>\n",
       "      <th>ur</th>\n",
       "      <th>want</th>\n",
       "      <th>we</th>\n",
       "      <th>week</th>\n",
       "      <th>what</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4459 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      back  but  call  come  day  dont  free  get  go  good  ...  today  txt  \\\n",
       "0        0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "1        0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "2        0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "3        0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "4        0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "...    ...  ...   ...   ...  ...   ...   ...  ...  ..   ...  ...    ...  ...   \n",
       "4454     1    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "4455     0    0     0     0    0     0     0    1   0     0  ...      0    0   \n",
       "4456     0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "4457     0    0     0     0    0     0     0    0   0     0  ...      0    0   \n",
       "4458     0    0     1     0    0     0     0    0   0     0  ...      0    0   \n",
       "\n",
       "      ur  want  we  week  what  work  you  label  \n",
       "0      0     0   0     0     0     0    0    ham  \n",
       "1      0     0   0     0     0     0    0    ham  \n",
       "2      0     0   0     0     0     0    0    NaN  \n",
       "3      0     0   0     0     0     0    0    ham  \n",
       "4      0     0   0     0     0     0    0    NaN  \n",
       "...   ..   ...  ..   ...   ...   ...  ...    ...  \n",
       "4454   0     0   0     0     0     0    0    NaN  \n",
       "4455   0     0   0     0     0     0    0    ham  \n",
       "4456   0     1   0     0     0     0    0    NaN  \n",
       "4457   0     0   0     0     0     0    0    ham  \n",
       "4458   0     0   0     0     0     0    0    NaN  \n",
       "\n",
       "[4459 rows x 51 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "# import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features = 50)\n",
    "X = vectorizer.fit_transform([i for i in training_data_clean['document_to_sklearn']])\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "df_bow_sklearn['label'] = training_data_clean['label']\n",
    "df_bow_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret[full]\n",
      "  Using cached pycaret-2.3.6-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: nltk in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (3.7)\n",
      "Requirement already satisfied: IPython in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (7.32.0)\n",
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.1-cp37-cp37m-win_amd64.whl (154 kB)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (1.0.1)\n",
      "Collecting mlflow\n",
      "  Using cached mlflow-1.23.1-py3-none-any.whl (15.6 MB)\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (0.23.2)\n",
      "Collecting pyyaml<6.0.0\n",
      "  Using cached PyYAML-5.4.1-cp37-cp37m-win_amd64.whl (210 kB)\n",
      "Collecting pyod\n",
      "  Using cached pyod-0.9.7-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'e:\\\\anaconda\\\\envs\\\\pycaret_env\\\\lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kmodes>=0.10.1\n",
      "  Using cached kmodes-0.11.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Collecting Boruta\n",
      "  Using cached Boruta-0.3-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: pandas in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (1.3.5)\n",
      "Collecting mlxtend>=0.17.0\n",
      "  Using cached mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting pyLDAvis\n",
      "  Using cached pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting plotly>=4.4.1\n",
      "  Using cached plotly-5.6.0-py2.py3-none-any.whl (27.7 MB)\n",
      "Collecting spacy<2.4.0\n",
      "  Using cached spacy-2.3.7-cp37-cp37m-win_amd64.whl (9.6 MB)\n",
      "Collecting cufflinks>=0.17.0\n",
      "  Using cached cufflinks-0.17.3-py3-none-any.whl\n",
      "Requirement already satisfied: seaborn in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (0.11.2)\n",
      "Collecting scikit-plot\n",
      "  Using cached scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (3.5.1)\n",
      "Requirement already satisfied: scipy<=1.5.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret[full]) (1.5.4)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "Collecting lightgbm>=2.3.1\n",
      "  Using cached lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting imbalanced-learn==0.7.0\n",
      "  Using cached imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "Collecting pandas-profiling>=2.8.0\n",
      "  Using cached pandas_profiling-3.1.0-py2.py3-none-any.whl (261 kB)\n",
      "Collecting gensim<4.0.0\n",
      "  Using cached gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2 MB)\n",
      "Collecting yellowbrick>=1.0.1\n",
      "  Using cached yellowbrick-1.4-py3-none-any.whl (274 kB)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.2-py3-none-any.whl\n",
      "Collecting scikit-optimize>=0.8.1\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting azure-storage-blob\n",
      "  Downloading azure_storage_blob-12.9.0-py2.py3-none-any.whl (356 kB)\n",
      "Collecting interpret<=0.2.4\n",
      "  Downloading interpret-0.2.4-py3-none-any.whl (1.4 kB)\n",
      "Collecting gradio\n",
      "  Downloading gradio-2.8.4-py3-none-any.whl (650 kB)\n",
      "Collecting catboost>=0.23.2\n",
      "  Downloading catboost-1.0.4-cp37-none-win_amd64.whl (73.5 MB)\n",
      "Collecting evidently\n",
      "  Downloading evidently-0.1.45.dev0-py3-none-any.whl (22.1 MB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.0-cp37-cp37m-win_amd64.whl (246 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.21.8-py3-none-any.whl (132 kB)\n",
      "Collecting autoviz\n",
      "  Downloading autoviz-0.1.36-py3-none-any.whl (59 kB)\n",
      "Collecting ray[tune]>=1.0.0\n",
      "  Downloading ray-1.10.0-cp37-cp37m-win_amd64.whl (22.9 MB)\n",
      "Collecting xgboost>=1.1.0\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Collecting explainerdashboard\n",
      "  Downloading explainerdashboard-0.3.8-py3-none-any.whl (305 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.17.5-py3-none-any.whl (53 kB)\n",
      "Collecting m2cgen\n",
      "  Downloading m2cgen-0.9.0-py3-none-any.whl (73 kB)\n",
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.74.1-py3-none-any.whl (53 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.1.0-py2.py3-none-any.whl (106 kB)\n",
      "Collecting shap\n",
      "  Downloading shap-0.40.0-cp37-cp37m-win_amd64.whl (430 kB)\n",
      "Collecting tune-sklearn>=0.2.1\n",
      "  Downloading tune_sklearn-0.4.1-py3-none-any.whl (40 kB)\n",
      "Collecting optuna>=2.2.0\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "Collecting fairlearn\n",
      "  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from imbalanced-learn==0.7.0->pycaret[full]) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-learn==0.23.2->pycaret[full]) (3.1.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: six in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from catboost>=0.23.2->pycaret[full]) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from cufflinks>=0.17.0->pycaret[full]) (58.0.4)\n",
      "Collecting colorlover>=0.2.1\n",
      "  Using cached colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Collecting Cython==0.29.14\n",
      "  Using cached Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4\n",
      "  Downloading interpret_core-0.2.7-py3-none-any.whl (6.6 MB)\n",
      "Collecting dill>=0.2.5\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting requests>=2.19.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting dash-table>=4.1.0\n",
      "  Downloading dash_table-5.0.0.tar.gz (3.4 kB)\n",
      "Collecting dash-cytoscape>=0.1.1\n",
      "  Downloading dash_cytoscape-0.3.0-py3-none-any.whl (3.6 MB)\n",
      "Collecting gevent>=1.3.6\n",
      "  Downloading gevent-21.12.0-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Collecting dash>=1.0.0\n",
      "  Downloading dash-2.2.0-py3-none-any.whl (8.5 MB)\n",
      "Collecting lime>=0.1.1.33\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "Collecting SALib>=1.3.3\n",
      "  Downloading SALib-1.4.5-py2.py3-none-any.whl (756 kB)\n",
      "Requirement already satisfied: ipykernel>=5.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (6.9.1)\n",
      "Collecting skope-rules>=1.0.1\n",
      "  Downloading skope_rules-1.0.1-py3-none-any.whl (14 kB)\n",
      "Collecting treeinterpreter>=0.2.2\n",
      "  Downloading treeinterpreter-0.2.3-py2.py3-none-any.whl (6.0 kB)\n",
      "Collecting flask-compress\n",
      "  Downloading Flask_Compress-1.10.1-py3-none-any.whl (7.9 kB)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Downloading dash_core_components-2.0.0.tar.gz (3.4 kB)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Downloading dash_html_components-2.0.0.tar.gz (3.8 kB)\n",
      "Collecting Flask>=1.0.4\n",
      "  Using cached Flask-2.0.3-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (8.0.4)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2.1.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from click>=7.1.2->Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from click>=7.1.2->Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (4.11.1)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.4.0-cp37-cp37m-win_amd64.whl (210 kB)\n",
      "Requirement already satisfied: cffi>=1.12.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (1.15.0)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (1.1.2)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from cffi>=1.12.2->gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2.21)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (5.1.1)\n",
      "Requirement already satisfied: nest-asyncio in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (1.5.4)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (7.1.2)\n",
      "Requirement already satisfied: decorator in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret[full]) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret[full]) (0.7.5)\n",
      "Requirement already satisfied: pygments in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret[full]) (2.11.2)\n",
      "Requirement already satisfied: backcall in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret[full]) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret[full]) (3.0.28)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret[full]) (0.18.1)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret[full]) (3.5.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret[full]) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret[full]) (5.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jedi>=0.16->IPython->pycaret[full]) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2.0.1)\n",
      "Requirement already satisfied: pyzmq>=13 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (4.9.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (227)\n",
      "Requirement already satisfied: wheel in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from lightgbm>=2.3.1->pycaret[full]) (0.37.1)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (4.62.3)\n",
      "Collecting scikit-image>=0.12\n",
      "  Downloading scikit_image-0.19.2-cp37-cp37m-win_amd64.whl (12.5 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret[full]) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret[full]) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret[full]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret[full]) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret[full]) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret[full]) (9.0.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret[full]) (4.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret[full]) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret[full]) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret[full]) (0.18.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret[full]) (4.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret[full]) (3.7.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from optuna>=2.2.0->pycaret[full]) (1.4.31)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.7.6-py3-none-any.whl (210 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas->pycaret[full]) (2021.3)\n",
      "Collecting htmlmin>=0.1.12\n",
      "  Using cached htmlmin-0.1.12-py3-none-any.whl\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.7.4)\n",
      "Requirement already satisfied: multimethod>=1.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (1.7)\n",
      "Collecting missingno>=0.4.2\n",
      "  Using cached missingno-0.5.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.1.0)\n",
      "Collecting pydantic>=1.8.1\n",
      "  Using cached pydantic-1.9.0-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Collecting phik>=0.11.1\n",
      "  Using cached phik-0.12.0-cp37-cp37m-win_amd64.whl (660 kB)\n",
      "Requirement already satisfied: networkx>=2.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret[full]) (2.6.3)\n",
      "Collecting imagehash\n",
      "  Using cached ImageHash-4.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tenacity>=6.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from plotly>=4.4.1->pycaret[full]) (8.0.1)\n",
      "Requirement already satisfied: wcwidth in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->pycaret[full]) (0.2.5)\n",
      "Collecting protobuf>=3.15.3\n",
      "  Using cached protobuf-3.19.4-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "Collecting grpcio>=1.28.1\n",
      "  Downloading grpcio-1.44.0-cp37-cp37m-win_amd64.whl (3.4 MB)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.3-cp37-cp37m-win_amd64.whl (68 kB)\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: tabulate in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ray[tune]>=1.0.0->pycaret[full]) (0.8.9)\n",
      "Collecting deprecated>=1.2.3\n",
      "  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.3-cp37-cp37m-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (3.3)\n",
      "Collecting pathos\n",
      "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4->pycaret[full]) (1.2.0)\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.16.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting numpy>=1.13.3\n",
      "  Using cached numpy-1.21.5-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Using cached thinc-7.4.5-cp37-cp37m-win_amd64.whl (888 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.5-cp37-cp37m-win_amd64.whl (6.5 MB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret[full]) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret[full]) (2.0.6)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp37-cp37m-win_amd64.whl (108 kB)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret[full]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret[full]) (1.0.6)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: notebook>=4.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (6.4.8)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (21.3.0)\n",
      "Requirement already satisfied: nbconvert in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (6.4.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.13.1)\n",
      "Requirement already satisfied: prometheus-client in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.13.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (2.0.2)\n",
      "Collecting yellowbrick>=1.0.1\n",
      "  Using cached yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
      "  Downloading yellowbrick-1.3-py3-none-any.whl (271 kB)\n",
      "  Downloading yellowbrick-1.2.1-py3-none-any.whl (269 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (21.2.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
      "Collecting fsspec==0.8.3\n",
      "  Downloading fsspec-0.8.3-py3-none-any.whl (88 kB)\n",
      "Collecting bokeh==2.4.2\n",
      "  Downloading bokeh-2.4.2-py3-none-any.whl (18.5 MB)\n",
      "Collecting holoviews==1.14.6\n",
      "  Downloading holoviews-1.14.6-py3-none-any.whl (4.3 MB)\n",
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.13.2-cp37-cp37m-win_amd64.whl (9.0 MB)\n",
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Collecting hvplot==0.7.3\n",
      "  Downloading hvplot-0.7.3-py2.py3-none-any.whl (3.1 MB)\n",
      "Collecting panel==0.12.6\n",
      "  Downloading panel-0.12.6-py2.py3-none-any.whl (12.9 MB)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting param<2.0,>=1.9.3\n",
      "  Downloading param-1.12.0-py2.py3-none-any.whl (85 kB)\n",
      "Collecting colorcet\n",
      "  Downloading colorcet-3.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting pyviz-comms>=0.7.4\n",
      "  Downloading pyviz_comms-2.1.0-py2.py3-none-any.whl (40 kB)\n",
      "Collecting markdown\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting pyct>=0.4.4\n",
      "  Downloading pyct-0.4.8-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: bleach in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from panel==0.12.6->autoviz->pycaret[full]) (4.1.0)\n",
      "Collecting msrest>=0.6.21\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting cryptography>=2.1.4\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-win_amd64.whl (2.2 MB)\n",
      "Collecting azure-core<2.0.0,>=1.10.0\n",
      "  Downloading azure_core-1.22.1-py3-none-any.whl (178 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: webencodings in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from bleach->panel==0.12.6->autoviz->pycaret[full]) (0.5.1)\n",
      "Collecting botocore<1.25.0,>=1.24.8\n",
      "  Downloading botocore-1.24.8-py3-none-any.whl (8.6 MB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting dataclasses>=0.6\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "Collecting dash-auth\n",
      "  Downloading dash_auth-1.4.1.tar.gz (470 kB)\n",
      "Collecting dtreeviz>=1.3\n",
      "  Downloading dtreeviz-1.3.3.tar.gz (61 kB)\n",
      "Collecting waitress\n",
      "  Using cached waitress-2.0.0-py3-none-any.whl (56 kB)\n",
      "Collecting oyaml\n",
      "  Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting flask-simplelogin\n",
      "  Downloading flask_simplelogin-0.1.1-py3-none-any.whl (7.2 kB)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.6.7-cp37-none-win_amd64.whl (186 kB)\n",
      "Collecting dash-bootstrap-components<1\n",
      "  Downloading dash_bootstrap_components-0.13.1-py3-none-any.whl (197 kB)\n",
      "Collecting jupyter-dash\n",
      "  Downloading jupyter_dash-0.4.1-py3-none-any.whl (17 kB)\n",
      "Collecting colour\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n",
      "Collecting chart_studio>=1.0.0\n",
      "  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
      "Collecting flask-seasurf\n",
      "  Downloading Flask_SeaSurf-0.3.1-py3-none-any.whl (8.1 kB)\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting ua_parser\n",
      "  Downloading ua_parser-0.10.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting starlette==0.17.1\n",
      "  Downloading starlette-0.17.1-py3-none-any.whl (58 kB)\n",
      "Collecting anyio<4,>=3.0.0\n",
      "  Downloading anyio-3.5.0-py3-none-any.whl (79 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp37-cp37m-win_amd64.whl (365 kB)\n",
      "Collecting WTForms>=2.1\n",
      "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
      "Collecting Flask-WTF<0.16.0,>=0.15.1\n",
      "  Downloading Flask_WTF-0.15.1-py2.py3-none-any.whl (13 kB)\n",
      "Collecting google-api-core<3.0dev,>=1.29.0\n",
      "  Downloading google_api_core-2.5.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-2.2.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-resumable-media>=1.3.0\n",
      "  Downloading google_resumable_media-2.3.0-py2.py3-none-any.whl (76 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.55.0-py2.py3-none-any.whl (212 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp37-cp37m-win_amd64.whl (27 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.14.1-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting analytics-python\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting paramiko\n",
      "  Downloading paramiko-2.9.2-py2.py3-none-any.whl (210 kB)\n",
      "Collecting python-multipart\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-win_amd64.whl (551 kB)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.0.1-py3-none-any.whl (84 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-win_amd64.whl (121 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-win_amd64.whl (33 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-win_amd64.whl (27 kB)\n",
      "Collecting backoff==1.10.0\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.2.2-py3-none-any.whl (120 kB)\n",
      "Collecting ansi2html\n",
      "  Downloading ansi2html-1.7.0-py3-none-any.whl (15 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.0-py3-none-any.whl (11 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "Collecting linkify-it-py~=1.0\n",
      "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting querystring-parser\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting docker>=4.0.0\n",
      "  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Using cached databricks_cli-0.16.4-py3-none-any.whl\n",
      "Collecting prometheus-flask-exporter\n",
      "  Using cached prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from docker>=4.0.0->mlflow->pycaret[full]) (1.3.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret[full]) (5.0.0)\n",
      "Requirement already satisfied: defusedxml in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.8.4)\n",
      "Requirement already satisfied: testpath in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.6.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.5.11)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nltk->pycaret[full]) (2022.1.18)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from numba->shap->pycaret[full]) (0.38.0)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-win_amd64.whl (212 kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-win_amd64.whl (28 kB)\n",
      "Collecting ppft>=1.6.6.4\n",
      "  Downloading ppft-1.6.6.4-py3-none-any.whl (65 kB)\n",
      "Collecting multiprocess>=0.70.12\n",
      "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "Collecting pox>=0.3.0\n",
      "  Downloading pox-0.3.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting funcy\n",
      "  Using cached funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: sklearn in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pyLDAvis->pycaret[full]) (0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numexpr\n",
      "  Using cached numexpr-2.8.1-cp37-cp37m-win_amd64.whl (88 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Downloading atomicwrites-1.4.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Collecting qtpy\n",
      "  Downloading QtPy-2.0.1-py3-none-any.whl (65 kB)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.6-py3-none-any.whl\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Collecting asgiref>=3.4.0\n",
      "  Downloading asgiref-3.5.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: dash-core-components, dash-html-components, dash-table, lime, pyperclip, emoji, dtreeviz, dash-auth, retrying, ffmpy, pyLDAvis, python-multipart\n",
      "  Building wheel for dash-core-components (setup.py): started\n",
      "  Building wheel for dash-core-components (setup.py): finished with status 'done'\n",
      "  Created wheel for dash-core-components: filename=dash_core_components-2.0.0-py3-none-any.whl size=3822 sha256=fa343371200f7be5b0ca211c13262b831dcad235b2053c5b31b65b399581aea5\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\00\\f9\\c7\\1a6437d794ed753ea9bc9079e761d4fc803a1f1f5d3697b9ec\n",
      "  Building wheel for dash-html-components (setup.py): started\n",
      "  Building wheel for dash-html-components (setup.py): finished with status 'done'\n",
      "  Created wheel for dash-html-components: filename=dash_html_components-2.0.0-py3-none-any.whl size=4090 sha256=ca40b08c1769cf31eac427649cb73161c4dd050854b5bede2a20d7a080f2ef1a\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\ec\\6b\\81\\05aceabd8b27f724e2c96784016287cc1bfbc349ebfda451de\n",
      "  Building wheel for dash-table (setup.py): started\n",
      "  Building wheel for dash-table (setup.py): finished with status 'done'\n",
      "  Created wheel for dash-table: filename=dash_table-5.0.0-py3-none-any.whl size=3912 sha256=d342d720352bf27ac1d95cc2215425fd1c943c6c5795803581dd5373b01a974b\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\85\\5d\\4e\\7c276b57992951dbe770bf5caad6448d0539c510663aefd2e2\n",
      "  Building wheel for lime (setup.py): started\n",
      "  Building wheel for lime (setup.py): finished with status 'done'\n",
      "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=95b980ea58e4c492a5959642981feae88d29ade9c9add98aa3df5221c7b4d3af\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\ca\\cb\\e5\\ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=0be151e5634d73e7cfe19d33cdff54ba39b64215087ed96bb054796a3b525ab3\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\9f\\18\\84\\8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=db84d85ef1c41e72f3a22265593485c0e529bbffd12d166c899c39b7d9e15e48\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\03\\8b\\d7\\ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
      "  Building wheel for dtreeviz (setup.py): started\n",
      "  Building wheel for dtreeviz (setup.py): finished with status 'done'\n",
      "  Created wheel for dtreeviz: filename=dtreeviz-1.3.3-py3-none-any.whl size=67113 sha256=a084a142ba84009c16ee36c9abafd57227e7aa377677dbbd0908247f4164bb5f\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\58\\9d\\65\\e57deb90bf5440945d74bc4c19ebb14a0de2ed2b508c609673\n",
      "  Building wheel for dash-auth (setup.py): started\n",
      "  Building wheel for dash-auth (setup.py): finished with status 'done'\n",
      "  Created wheel for dash-auth: filename=dash_auth-1.4.1-py3-none-any.whl size=476152 sha256=b0f1442ab9d2ae91cd18abf410fecd8b2659878d6a4be584d40cc5df32cce4bb\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\19\\b2\\02\\3c3f05988ff92f02c52ce4e081859d423537e8e9b13f673c02\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=1bec34dcf0f75ee87ecb8fe1a0d5aaacf7d7fe6733f1130f59ba808e06ae8165\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\f9\\8d\\8d\\f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=a6c686191027bdd31cea8326e1511c80196718c27f2fbd087c37a62a94666ee5\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\13\\e4\\6c\\e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
      "  Building wheel for pyLDAvis (PEP 517): started\n",
      "  Building wheel for pyLDAvis (PEP 517): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136900 sha256=f012cb6ba61bd070cb5209ce60120f3d9b9dd66fee840ce9f234f4abe6754adb\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\c9\\21\\f6\\17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
      "  Building wheel for python-multipart (setup.py): started\n",
      "  Building wheel for python-multipart (setup.py): finished with status 'done'\n",
      "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=83d5df5a712009232a8049368bb18e85c60c1e9ce9dec2e7226178ec0e915716\n",
      "  Stored in directory: c:\\users\\aadar\\appdata\\local\\pip\\cache\\wheels\\2c\\41\\7c\\bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
      "Successfully built dash-core-components dash-html-components dash-table lime pyperclip emoji dtreeviz dash-auth retrying ffmpy pyLDAvis python-multipart\n",
      "Installing collected packages: wrapt, pyyaml, pyasn1, param, numpy, Flask, dill, brotli, tifffile, sniffio, rsa, requests, pyviz-comms, pyct, pyasn1-modules, protobuf, ppft, pox, plotly, multiprocess, mdurl, markdown, imageio, flask-compress, deprecated, dash-table, dash-html-components, dash-core-components, cachetools, bokeh, zope.interface, zope.event, WTForms, uc-micro-py, tomli, smart-open, slicer, scikit-image, retrying, redis, qtpy, pyreadline3, pyperclip, py, preshed, pluggy, plac, pbr, patsy, pathos, panel, oauthlib, numba, multidict, msgpack, markdown-it-py, Mako, jupyterlab-widgets, jmespath, iniconfig, imagehash, grpcio, googleapis-common-protos, google-auth, gitdb, frozenlist, filelock, dash, Cython, colorcet, cloudpickle, catalogue, blis, atomicwrites, anyio, yarl, waitress, ua-parser, treeinterpreter, thinc, tensorboardX, stevedore, statsmodels, starlette, sqlparse, skope-rules, shap, SALib, requests-oauthlib, ray, querystring-parser, qtconsole, pytest, pynndescent, pynacl, pydantic, psutil, prometheus-flask-exporter, PrettyTable, phik, numexpr, monotonic, missingno, mdit-py-plugins, linkify-it-py, lime, jupyter-console, isodate, ipywidgets, interpret-core, htmlmin, holoviews, h11, graphviz, google-crc32c, google-api-core, gitpython, gevent, gensim, future, funcy, Flask-WTF, flask-seasurf, docker, databricks-cli, dash-cytoscape, cryptography, colour, colorlover, cmd2, chart-studio, botocore, bcrypt, backoff, autopage, asynctest, async-timeout, asgiref, ansi2html, alembic, aiosignal, yellowbrick, xlrd, xgboost, wordcloud, uvicorn, umap-learn, textblob, spacy, scikit-plot, s3transfer, python-multipart, pyod, pyLDAvis, pydub, pycryptodome, pyaml, py4j, paramiko, pandas-profiling, oyaml, orjson, msrest, mlxtend, mlflow, lightgbm, kmodes, jupyter-dash, jupyter, imbalanced-learn, hvplot, google-resumable-media, google-cloud-core, fsspec, flask-simplelogin, ffmpy, fastapi, emoji, dtreeviz, dataclasses, dash-bootstrap-components, dash-auth, cufflinks, colorlog, cmaes, cliff, Boruta, azure-core, analytics-python, aiohttp, tune-sklearn, scikit-optimize, pycaret, optuna, m2cgen, interpret, hyperopt, gradio, google-cloud-storage, fairlearn, explainerdashboard, evidently, catboost, boto3, azure-storage-blob, autoviz\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycaret[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUvFcpTY5Upy",
    "outputId": "8063c021-b0c8-4f7d-9a5d-2dcbbb8a9c12",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycaret in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: pandas-profiling>=2.8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (3.1.0)\n",
      "Requirement already satisfied: seaborn in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.11.2)\n",
      "Requirement already satisfied: cufflinks>=0.17.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.17.3)\n",
      "Requirement already satisfied: umap-learn in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.5.2)\n",
      "Requirement already satisfied: gensim<4.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (3.8.3)\n",
      "Requirement already satisfied: spacy<2.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (2.3.7)\n",
      "Requirement already satisfied: ipywidgets in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (7.6.5)\n",
      "Requirement already satisfied: pandas in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (1.3.5)\n",
      "Requirement already satisfied: imbalanced-learn==0.7.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.7.0)\n",
      "Requirement already satisfied: IPython in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (7.32.0)\n",
      "Requirement already satisfied: textblob in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.17.1)\n",
      "Requirement already satisfied: pyod in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.9.7)\n",
      "Requirement already satisfied: scikit-plot in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.3.7)\n",
      "Requirement already satisfied: mlflow in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (1.23.1)\n",
      "Requirement already satisfied: nltk in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (3.7)\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.23.2)\n",
      "Requirement already satisfied: scipy<=1.5.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (1.5.4)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (1.0.1)\n",
      "Requirement already satisfied: kmodes>=0.10.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.11.1)\n",
      "Requirement already satisfied: mlxtend>=0.17.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.19.0)\n",
      "Collecting numpy==1.19.5\n",
      "  Using cached numpy-1.19.5-cp37-cp37m-win_amd64.whl (13.2 MB)\n",
      "Requirement already satisfied: pyLDAvis in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (3.2.2)\n",
      "Requirement already satisfied: plotly>=4.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (5.6.0)\n",
      "Requirement already satisfied: Boruta in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (0.3)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (3.3.2)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (3.5.1)\n",
      "Requirement already satisfied: yellowbrick>=1.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (1.3.post1)\n",
      "Requirement already satisfied: wordcloud in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pycaret) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-learn==0.23.2->pycaret) (3.1.0)\n",
      "Requirement already satisfied: colorlover>=0.2.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from cufflinks>=0.17.0->pycaret) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from cufflinks>=0.17.0->pycaret) (58.0.4)\n",
      "Requirement already satisfied: Cython==0.29.14 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gensim<4.0.0->pycaret) (0.29.14)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
      "Requirement already satisfied: pygments in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (2.11.2)\n",
      "Requirement already satisfied: matplotlib-inline in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (5.1.1)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (3.0.28)\n",
      "Requirement already satisfied: backcall in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (0.2.0)\n",
      "Requirement already satisfied: decorator in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from IPython->pycaret) (5.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret) (3.5.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret) (6.9.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipywidgets->pycaret) (1.0.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (1.5.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jedi>=0.16->IPython->pycaret) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pycaret) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pycaret) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pycaret) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pycaret) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pycaret) (227)\n",
      "Requirement already satisfied: wheel in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from lightgbm>=2.3.1->pycaret) (0.37.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from matplotlib->pycaret) (0.11.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (4.11.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (4.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.7.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas->pycaret) (2021.3)\n",
      "Requirement already satisfied: requests>=2.24.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (2.27.1)\n",
      "Requirement already satisfied: missingno>=0.4.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (4.62.3)\n",
      "Requirement already satisfied: multimethod>=1.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (1.7)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (0.7.4)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (3.0.3)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (5.4.1)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (1.9.0)\n",
      "Requirement already satisfied: markupsafe~=2.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.0)\n",
      "Requirement already satisfied: phik>=0.11.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pandas-profiling>=2.8.0->pycaret) (0.12.0)\n",
      "Requirement already satisfied: networkx>=2.4 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (2.6.3)\n",
      "Requirement already satisfied: imagehash in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (4.2.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from plotly>=4.4.1->pycaret) (8.0.1)\n",
      "Requirement already satisfied: wcwidth in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->pycaret) (0.2.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.10.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.26.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (0.9.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (7.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (0.7.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.4.8)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
      "Requirement already satisfied: nbconvert in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.4.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.13.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.15.0)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (2.21)\n",
      "Requirement already satisfied: PyWavelets in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.2.0)\n",
      "Requirement already satisfied: sqlalchemy in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (1.4.31)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (3.1.27)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (0.4.2)\n",
      "Requirement already satisfied: docker>=4.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (5.0.3)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (0.16.4)\n",
      "Requirement already satisfied: prometheus-flask-exporter in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (0.18.7)\n",
      "Requirement already satisfied: querystring-parser in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (1.2.4)\n",
      "Requirement already satisfied: alembic in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (1.7.6)\n",
      "Requirement already satisfied: waitress in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (2.0.0)\n",
      "Requirement already satisfied: Flask in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (2.0.3)\n",
      "Requirement already satisfied: click>=7.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (2.0.0)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from mlflow->pycaret) (3.19.4)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from docker>=4.0.0->mlflow->pycaret) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (5.0.0)\n",
      "Requirement already satisfied: Mako in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from alembic->mlflow->pycaret) (1.1.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from sqlalchemy->mlflow->pycaret) (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Flask->mlflow->pycaret) (2.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from Flask->mlflow->pycaret) (2.1.0)\n",
      "Requirement already satisfied: bleach in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
      "Requirement already satisfied: testpath in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.11)\n",
      "Requirement already satisfied: webencodings in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from nltk->pycaret) (2022.1.18)\n",
      "Requirement already satisfied: numexpr in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pyLDAvis->pycaret) (2.8.1)\n",
      "Requirement already satisfied: future in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pyLDAvis->pycaret) (0.18.2)\n",
      "Requirement already satisfied: funcy in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pyLDAvis->pycaret) (1.17)\n",
      "Requirement already satisfied: statsmodels in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pyod->pycaret) (0.13.2)\n",
      "Requirement already satisfied: numba>=0.35 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from pyod->pycaret) (0.55.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from numba>=0.35->pyod->pycaret) (0.38.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from statsmodels->pyod->pycaret) (0.5.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from umap-learn->pycaret) (0.5.6)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 0.23.2\n",
      "Uninstalling scikit-learn-0.23.2:\n",
      "  Successfully uninstalled scikit-learn-0.23.2\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Using cached scikit_learn-0.23.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-learn==0.23.2) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-learn==0.23.2) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-learn==0.23.2) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\envs\\pycaret_env\\lib\\site-packages (from scikit-learn==0.23.2) (3.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-0.23.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# !pip freeze\n",
    "# !pip install pycaret==2.3.5\n",
    "!pip install pycaret\n",
    "!pip uninstall scikit-learn -y\n",
    "!pip install scikit-learn==0.23.2\n",
    "# !pip install numpy --upgrade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "z-_V7_0g5k48"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_raise_dep_warning_if_not_pytest' from 'sklearn.utils.deprecation' (E:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16856\\2855532037.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Modeling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m s = setup(data = df_bow_sklearn, target='label',\n\u001b[0;32m      4\u001b[0m           \u001b[0mnumeric_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           session_id=123,verbose=False,silent=True)\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\pycaret\\classification.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtabular\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_in_colab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_colab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\pycaret\\internal\\tabular.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mget_estimator_from_meta_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[1;33m from pycaret.internal.pipeline import (\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0madd_estimator_to_pipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mget_pipeline_estimator_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\pycaret\\internal\\pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_all_object_vars_and_properties\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_fit_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\imblearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\imblearn\\combine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\imblearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_docstring\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSubstitution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_neighbors_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\neighbors\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_kde\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKernelDensity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lof\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLocalOutlierFactor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_nca\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNeighborhoodComponentsAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVALID_METRICS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVALID_METRICS_SPARSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\neighbors\\_nca.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\decomposition\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdict_learning\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdict_learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\decomposition\\dict_learning.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_dict_learning\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pep562\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPep562\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_raise_dep_warning_if_not_pytest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdeprecated_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sklearn.decomposition.dict_learning'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_raise_dep_warning_if_not_pytest' from 'sklearn.utils.deprecation' (E:\\Anaconda\\envs\\pycaret_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py)"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "from pycaret.classification import *\n",
    "s = setup(data = df_bow_sklearn, target='label',\n",
    "          numeric_features=vectorizer.get_feature_names(),\n",
    "          session_id=123,verbose=False,silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425,
     "referenced_widgets": [
      "29a3ab7cbbef4515bbbe0150faedfa38",
      "ec52b60fa380445687109957860a7c59",
      "80f5ebafa5394053a6ecd597d677ae44"
     ]
    },
    "id": "EVrY3J3N5obV",
    "outputId": "7134f8b8-be1b-4703-bb87-4da58f42c226"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-514ef9b6-4792-4987-b094-ecbbf0a120a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>-0.0728</td>\n",
       "      <td>-0.1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>-0.0590</td>\n",
       "      <td>-0.1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>-0.0398</td>\n",
       "      <td>-0.0734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.2062</td>\n",
       "      <td>-0.0165</td>\n",
       "      <td>-0.0309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.4703</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>-0.0313</td>\n",
       "      <td>-0.0590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4520</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-514ef9b6-4792-4987-b094-ecbbf0a120a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-514ef9b6-4792-4987-b094-ecbbf0a120a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-514ef9b6-4792-4987-b094-ecbbf0a120a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.3720  0.4058  0.4545  0.0974  0.1604 -0.0728 -0.1295\n",
       "1       0.4640  0.5532  0.6970  0.1565  0.2556  0.0509  0.0863\n",
       "2       0.3520  0.3820  0.5152  0.1043  0.1735 -0.0590 -0.1120\n",
       "3       0.3760  0.4506  0.5455  0.1132  0.1875 -0.0398 -0.0734\n",
       "4       0.3840  0.4899  0.6061  0.1242  0.2062 -0.0165 -0.0309\n",
       "5       0.4080  0.5699  0.7576  0.1515  0.2525  0.0417  0.0803\n",
       "6       0.4120  0.5284  0.7273  0.1481  0.2462  0.0344  0.0647\n",
       "7       0.3720  0.4703  0.5758  0.1173  0.1949 -0.0313 -0.0590\n",
       "8       0.4520  0.5846  0.7273  0.1579  0.2595  0.0543  0.0953\n",
       "9       0.4360  0.5698  0.7576  0.1582  0.2618  0.0555  0.1015\n",
       "Mean    0.4028  0.5004  0.6364  0.1329  0.2198  0.0017  0.0023\n",
       "SD      0.0360  0.0684  0.1050  0.0228  0.0373  0.0481  0.0875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = create_model('nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "4398ce3d46cf48c28f08b15a328717e4",
      "572c6aaecb274e919cdfa46acf41c0c1",
      "4eac1595433b49588e4117d3eedd672c"
     ]
    },
    "id": "RrEvuVeC5sTQ",
    "outputId": "1266b4bc-63c4-40bb-a43e-10e22eebf964"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-de04c084-4c29-407e-9081-e089160775d0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.4206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>-0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>-0.0189</td>\n",
       "      <td>-0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0260</td>\n",
       "      <td>-0.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de04c084-4c29-407e-9081-e089160775d0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-de04c084-4c29-407e-9081-e089160775d0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-de04c084-4c29-407e-9081-e089160775d0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8700  0.5441  0.0303  0.6667  0.0580  0.0470  0.1227\n",
       "1       0.8560  0.4892  0.0455  0.2500  0.0769  0.0378  0.0547\n",
       "2       0.8640  0.4206  0.0303  0.3333  0.0556  0.0343  0.0656\n",
       "3       0.8560  0.4852  0.0000  0.0000  0.0000 -0.0225 -0.0430\n",
       "4       0.8600  0.5198  0.0303  0.2500  0.0541  0.0263  0.0445\n",
       "...        ...     ...     ...     ...     ...     ...     ...\n",
       "497     0.8460  0.5349  0.0152  0.0769  0.0253 -0.0189 -0.0266\n",
       "498     0.8540  0.4588  0.0000  0.0000  0.0000 -0.0260 -0.0465\n",
       "499     0.8640  0.4731  0.0455  0.3750  0.0811  0.0541  0.0915\n",
       "Mean    0.8578  0.4901  0.0179  0.1748  0.0316  0.0057  0.0120\n",
       "SD      0.0078  0.0313  0.0154  0.1742  0.0264  0.0248  0.0474\n",
       "\n",
       "[502 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=100, random_state=1)\n",
    "# model = create_model('knn', fold=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488,
     "referenced_widgets": [
      "7a627c7397f040b597dcc79948f7365c",
      "2b889f2629d54138bf3eaeb8dbed431e",
      "55612a2d67a648df97b20eda9373d3a4"
     ]
    },
    "id": "XuGmzAT-6ZsY",
    "outputId": "672cf11b-5a3d-445f-9dfd-a76546170991"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f0928bd8-e6c2-40ea-bcff-4d8b59d22cb3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.8280</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.4847</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0015</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.8624</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0257</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0928bd8-e6c2-40ea-bcff-4d8b59d22cb3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f0928bd8-e6c2-40ea-bcff-4d8b59d22cb3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f0928bd8-e6c2-40ea-bcff-4d8b59d22cb3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "nb                            Naive Bayes    0.4028  0.5004  0.6364  0.1329   \n",
       "dt               Decision Tree Classifier    0.8280  0.5016  0.0545  0.1225   \n",
       "et                 Extra Trees Classifier    0.8412  0.4786  0.0303  0.1116   \n",
       "rf               Random Forest Classifier    0.8520  0.4821  0.0273  0.1571   \n",
       "knn                K Neighbors Classifier    0.8592  0.4898  0.0182  0.1936   \n",
       "lightgbm  Light Gradient Boosting Machine    0.8684  0.4847  0.0121  0.3500   \n",
       "ada                  Ada Boost Classifier    0.8652  0.4956  0.0061  0.1000   \n",
       "lda          Linear Discriminant Analysis    0.8664  0.4939  0.0030  0.0500   \n",
       "lr                    Logistic Regression    0.8672  0.4952  0.0000  0.0000   \n",
       "svm                   SVM - Linear Kernel    0.8672  0.0000  0.0000  0.0000   \n",
       "ridge                    Ridge Classifier    0.8680  0.0000  0.0000  0.0000   \n",
       "qda       Quadratic Discriminant Analysis    0.8680  0.5000  0.0000  0.0000   \n",
       "gbc          Gradient Boosting Classifier    0.8624  0.4950  0.0000  0.0000   \n",
       "dummy                    Dummy Classifier    0.8680  0.5000  0.0000  0.0000   \n",
       "\n",
       "              F1   Kappa     MCC  TT (Sec)  \n",
       "nb        0.2198  0.0017  0.0023     0.023  \n",
       "dt        0.0753 -0.0010 -0.0028     0.034  \n",
       "et        0.0472 -0.0077 -0.0104     0.703  \n",
       "rf        0.0458  0.0073  0.0110     0.727  \n",
       "knn       0.0318  0.0083  0.0176     0.143  \n",
       "lightgbm  0.0234  0.0181  0.0536     0.126  \n",
       "ada       0.0114  0.0031  0.0051     0.181  \n",
       "lda       0.0057  0.0011 -0.0001     0.041  \n",
       "lr        0.0000 -0.0016 -0.0049     0.039  \n",
       "svm       0.0000 -0.0015 -0.0035     0.039  \n",
       "ridge     0.0000  0.0000  0.0000     0.020  \n",
       "qda       0.0000  0.0000  0.0000     0.031  \n",
       "gbc       0.0000 -0.0107 -0.0257     0.259  \n",
       "dummy     0.0000  0.0000  0.0000     0.018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "com  = compare_models(sort='F1') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCBD-tuz8Qy1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week6_GrpB_Proj2B_NLP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "29a3ab7cbbef4515bbbe0150faedfa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80f5ebafa5394053a6ecd597d677ae44",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec52b60fa380445687109957860a7c59",
      "value": 4
     }
    },
    "2b889f2629d54138bf3eaeb8dbed431e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4398ce3d46cf48c28f08b15a328717e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4eac1595433b49588e4117d3eedd672c",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_572c6aaecb274e919cdfa46acf41c0c1",
      "value": 4
     }
    },
    "4eac1595433b49588e4117d3eedd672c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55612a2d67a648df97b20eda9373d3a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "572c6aaecb274e919cdfa46acf41c0c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a627c7397f040b597dcc79948f7365c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55612a2d67a648df97b20eda9373d3a4",
      "max": 74,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b889f2629d54138bf3eaeb8dbed431e",
      "value": 74
     }
    },
    "80f5ebafa5394053a6ecd597d677ae44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec52b60fa380445687109957860a7c59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
